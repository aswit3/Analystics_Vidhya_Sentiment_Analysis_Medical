{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswit3/Analystics_Vidhya_Sentiment_Analysis_Medical/blob/master/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDCh2K2n_oQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "844a8d5f-41ef-46e2-a5db-5d0e96678f29"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh4Skja9Afn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3EEGxMv-iwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr = pd.read_csv(\"drive/My Drive/datasets/Sentiment_Analysis_Analytics_vidhya_Medical/train_F3WbcTw.csv\")\n",
        "te = pd.read_csv(\"drive/My Drive/datasets/Sentiment_Analysis_Analytics_vidhya_Medical/test_tOlRoBf.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu3-t0ufCOP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4266e1b8-4546-4138-dd2e-04e8cfb362d0"
      },
      "source": [
        "tr.shape, te.shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5279, 4), (2924, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SORo5JLTCzTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "ff276633-0c5f-4b80-e2e1-8a644cbda7b0"
      },
      "source": [
        "tr.head(2)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>text</th>\n",
              "      <th>drug</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0</td>\n",
              "      <td>Autoimmune diseases tend to come in clusters. ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9eba8f80e7e20f3a2f48685530748fbfa95943e4</td>\n",
              "      <td>I can completely understand why you’d want to ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                unique_hash  ... sentiment\n",
              "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0  ...         2\n",
              "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4  ...         2\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iws8Gf7DC42w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "6e91f31f-90a7-44e2-f5a8-02844d433f69"
      },
      "source": [
        "te.head(2)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>text</th>\n",
              "      <th>drug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
              "      <td>256 (previously stable on natalizumab), with 5...</td>\n",
              "      <td>fingolimod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
              "      <td>On fingolimod and have been since December 201...</td>\n",
              "      <td>fingolimod</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                unique_hash  ...        drug\n",
              "0  9e9a8166b84114aca147bf409f6f956635034c08  ...  fingolimod\n",
              "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a  ...  fingolimod\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DcoLyVDCtz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del tr[\"unique_hash\"]\n",
        "del te[\"unique_hash\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B0vwO3_I1Q7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c719ad5f-ab26-43f4-ca1b-2311dcd177ec"
      },
      "source": [
        "len(tr[\"drug\"].value_counts()), len(te[\"drug\"].value_counts())"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 95)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhkaA2TxDNhU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7cdfde66-125d-487c-b68e-6374fcbff4bd"
      },
      "source": [
        "tr.shape, te.shape"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5279, 3), (2924, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tjqvCaACaFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "966629c4-c528-43f8-ce1c-c590f0441278"
      },
      "source": [
        "tr_sentiment = tr[\"sentiment\"]\n",
        "tr_sentiment.shape"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5279,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNnQQ7gUHVQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del tr[\"sentiment\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6B-EFIGHd_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7c1badb-d930-455b-da98-ae869108b2fe"
      },
      "source": [
        "tr.shape, te.shape"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5279, 2), (2924, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_aa4n5bHte6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trte = tr.append(te, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDywZ15AIN_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf4729e5-51a6-4696-9c57-2229d0f13da5"
      },
      "source": [
        "trte.shape"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8203, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_js6iwUG5t_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5fdb2283-c895-4603-dd7b-efcbd669e52c"
      },
      "source": [
        "len(trte[\"drug\"].value_counts())"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qh_tIPJHHcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "clean_list = []\n",
        "\n",
        "for i, unclean_text in enumerate(trte[\"text\"]):\n",
        "  clean_text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', '', unclean_text)\n",
        "  clean_list.append(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBckeSFzOSyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trte[\"text\"] = clean_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsjTXJDvNGQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re, string, unicodedata\n",
        "import inflect\n",
        "import nltk\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuqLQn85NfFp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1c6de4a7-c0c3-4468-8cf6-0b6c3c3ccedb"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCrKTgO4NkbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_non_ascii(words):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def to_lowercase(words):\n",
        "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def replace_numbers(words):\n",
        "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
        "    p = inflect.engine()\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word.isdigit():\n",
        "            new_word = p.number_to_words(word)\n",
        "            new_words.append(new_word)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word not in stopwords.words('english'):\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def stem_words(words):\n",
        "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
        "    stemmer = LancasterStemmer()\n",
        "    stems = []\n",
        "    for word in words:\n",
        "        stem = stemmer.stem(word)\n",
        "        stems.append(stem)\n",
        "    return stems\n",
        "\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "def normalize(words):\n",
        "    words = remove_non_ascii(words)\n",
        "    words = to_lowercase(words)\n",
        "    words = remove_punctuation(words)\n",
        "    words = replace_numbers(words)\n",
        "    words = remove_stopwords(words)\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZbvl46qNvy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_ls = []\n",
        "for i, unclean_text in enumerate(trte[\"text\"]):\n",
        "  words = nltk.word_tokenize(unclean_text)\n",
        "  words = normalize(words)\n",
        "  words_ls.append(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8XGbdQJN6K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trte['text'] = words_ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoqKGQ0jPbu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_tokens =trte['text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdhSQD91Pwq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5W5JamxPeU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a102d3e4-ab69-4f8a-9745-601a0742b983"
      },
      "source": [
        "model_w2v = gensim.models.Word2Vec(\n",
        "            text_tokens,\n",
        "            size=200, # desired no. of features/independent variables \n",
        "            window=5, # context window size\n",
        "            min_count=2,\n",
        "            sg = 1, # 1 for skip-gram model\n",
        "            hs = 0,\n",
        "            negative = 10, # for negative sampling\n",
        "            workers= 2, # no.of cores\n",
        "            seed = 34)\n",
        "\n",
        "model_w2v.train(text_tokens, total_examples= len(tr['text']), epochs=10)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16454584, 17206770)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt5xX7hCQAxo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "dfee45af-53de-485a-d193-4ef2c9a41765"
      },
      "source": [
        "model_w2v.save(\"drive/My Drive/datasets/Sentiment_Analysis_Analytics_vidhya_Medical/word2vec.model\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwweVW3iQmno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "44cd3476-090e-4851-aec6-1247aafe52a2"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "model_w2v = Word2Vec.load(\"drive/My Drive/datasets/Sentiment_Analysis_Analytics_vidhya_Medical/word2vec.model\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh7Qve6cRBml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "8af41943-269c-485c-cfcb-abc162a33f46"
      },
      "source": [
        "model_w2v.wv.most_similar(positive=\"fingolimod\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('rebound', 0.6422704458236694),\n",
              " ('gilenya', 0.6394204497337341),\n",
              " ('natalizumab', 0.6385238170623779),\n",
              " ('teriflunomide', 0.6147090196609497),\n",
              " ('n257', 0.6009764671325684),\n",
              " ('alemtuzumab', 0.6003761887550354),\n",
              " ('categorizes', 0.5999492406845093),\n",
              " ('dimethyl', 0.597201943397522),\n",
              " ('one thousand, one hundred and sixty', 0.5943523645401001),\n",
              " ('lemtradatm', 0.585485577583313)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN5AvywfRNeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_vector(tokens, size):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0.\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += model_w2v[word].reshape((1, size))\n",
        "            count += 1.\n",
        "        except KeyError: # handling the case where the token is not in vocabulary\n",
        "                         \n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a0-SJVkRVG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "0365b1dd-6264-4bbe-b858-ddbcf6b8ba72"
      },
      "source": [
        "import numpy as np\n",
        "wordvec_arrays = np.zeros((len(text_tokens), 200))\n",
        "\n",
        "for i in range(len(text_tokens)):\n",
        "    wordvec_arrays[i,:] = word_vector(text_tokens[i], 200)\n",
        "    \n",
        "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
        "wordvec_df.shape"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8203, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFqgBMsFX8dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_sentiment = tr_sentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MISFQdpvRcTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0defb68f-0f73-4c72-c541-17721ff29707"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_w2v = wordvec_df.iloc[:5279,:]\n",
        "test_w2v = wordvec_df.iloc[5279:,:]\n",
        "\n",
        "\n",
        "_, _, ytrain, yvalid = train_test_split(train_w2v, tr_sentiment,  \n",
        "                                                          random_state=42, \n",
        "                                                          test_size=0.3)\n",
        "\n",
        "\n",
        "\n",
        "print(train_w2v.shape, tr_sentiment.shape)\n",
        "\n",
        "xtrain_w2v = train_w2v.iloc[ytrain.index,:]\n",
        "xvalid_w2v = train_w2v.iloc[yvalid.index,:]"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5279, 200) (5279,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Eu7BzI2SflA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras.layers as layers\n",
        "from keras.models import Model\n",
        "from keras.datasets import imdb\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import FastText\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import Input,Embedding,Dense,Flatten\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhi-_ujQSoPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "07aad7aa-1808-48b3-9aaf-86c6cfb9a4c8"
      },
      "source": [
        "epochs = 25\n",
        "batch_size = 1024\n",
        "loss = \"sparse_categorical_crossentropy\"\n",
        "optimizer = \"adam\"\n",
        "metrics = [\"accuracy\"]\n",
        "\n",
        "from keras import models\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
        "            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(200,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss=loss,optimizer=optimizer,metrics= metrics)\n",
        "model.fit(xtrain_w2v,ytrain,epochs=epochs,batch_size=batch_size,callbacks=callbacks,validation_data=(xvalid_w2v,yvalid))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3695 samples, validate on 1584 samples\n",
            "Epoch 1/25\n",
            "3695/3695 [==============================] - 1s 204us/step - loss: 0.9446 - acc: 0.5778 - val_loss: 0.7940 - val_acc: 0.7210\n",
            "Epoch 2/25\n",
            "3695/3695 [==============================] - 0s 49us/step - loss: 0.7965 - acc: 0.7261 - val_loss: 0.7737 - val_acc: 0.7210\n",
            "Epoch 3/25\n",
            "3695/3695 [==============================] - 0s 43us/step - loss: 0.7611 - acc: 0.7261 - val_loss: 0.7662 - val_acc: 0.7210\n",
            "Epoch 4/25\n",
            "3695/3695 [==============================] - 0s 57us/step - loss: 0.7544 - acc: 0.7261 - val_loss: 0.7520 - val_acc: 0.7210\n",
            "Epoch 5/25\n",
            "3695/3695 [==============================] - 0s 60us/step - loss: 0.7388 - acc: 0.7261 - val_loss: 0.7443 - val_acc: 0.7210\n",
            "Epoch 6/25\n",
            "3695/3695 [==============================] - 0s 58us/step - loss: 0.7289 - acc: 0.7261 - val_loss: 0.7321 - val_acc: 0.7210\n",
            "Epoch 7/25\n",
            "3695/3695 [==============================] - 0s 59us/step - loss: 0.7194 - acc: 0.7261 - val_loss: 0.7330 - val_acc: 0.7210\n",
            "Epoch 8/25\n",
            "3695/3695 [==============================] - 0s 60us/step - loss: 0.7140 - acc: 0.7261 - val_loss: 0.7200 - val_acc: 0.7210\n",
            "Epoch 9/25\n",
            "3695/3695 [==============================] - 0s 58us/step - loss: 0.7056 - acc: 0.7275 - val_loss: 0.7142 - val_acc: 0.7222\n",
            "Epoch 10/25\n",
            "3695/3695 [==============================] - 0s 56us/step - loss: 0.7013 - acc: 0.7267 - val_loss: 0.7143 - val_acc: 0.7235\n",
            "Epoch 11/25\n",
            "3695/3695 [==============================] - 0s 56us/step - loss: 0.6925 - acc: 0.7307 - val_loss: 0.7046 - val_acc: 0.7254\n",
            "Epoch 12/25\n",
            "3695/3695 [==============================] - 0s 57us/step - loss: 0.6839 - acc: 0.7321 - val_loss: 0.7052 - val_acc: 0.7241\n",
            "Epoch 13/25\n",
            "3695/3695 [==============================] - 0s 57us/step - loss: 0.6784 - acc: 0.7307 - val_loss: 0.6962 - val_acc: 0.7304\n",
            "Epoch 14/25\n",
            "3695/3695 [==============================] - 0s 58us/step - loss: 0.6710 - acc: 0.7367 - val_loss: 0.6992 - val_acc: 0.7241\n",
            "Epoch 15/25\n",
            "3695/3695 [==============================] - 0s 57us/step - loss: 0.6657 - acc: 0.7315 - val_loss: 0.6945 - val_acc: 0.7367\n",
            "Epoch 16/25\n",
            "3695/3695 [==============================] - 0s 60us/step - loss: 0.6599 - acc: 0.7396 - val_loss: 0.7055 - val_acc: 0.7229\n",
            "Epoch 17/25\n",
            "3695/3695 [==============================] - 0s 59us/step - loss: 0.6567 - acc: 0.7369 - val_loss: 0.6911 - val_acc: 0.7361\n",
            "Epoch 18/25\n",
            "3695/3695 [==============================] - 0s 59us/step - loss: 0.6463 - acc: 0.7448 - val_loss: 0.6979 - val_acc: 0.7266\n",
            "Epoch 19/25\n",
            "3695/3695 [==============================] - 0s 57us/step - loss: 0.6434 - acc: 0.7413 - val_loss: 0.6886 - val_acc: 0.7323\n",
            "Epoch 20/25\n",
            "3695/3695 [==============================] - 0s 56us/step - loss: 0.6342 - acc: 0.7453 - val_loss: 0.6853 - val_acc: 0.7292\n",
            "Epoch 21/25\n",
            "3695/3695 [==============================] - 0s 57us/step - loss: 0.6264 - acc: 0.7483 - val_loss: 0.6784 - val_acc: 0.7348\n",
            "Epoch 22/25\n",
            "3695/3695 [==============================] - 0s 55us/step - loss: 0.6192 - acc: 0.7467 - val_loss: 0.6830 - val_acc: 0.7348\n",
            "Epoch 23/25\n",
            "3695/3695 [==============================] - 0s 56us/step - loss: 0.6103 - acc: 0.7524 - val_loss: 0.6877 - val_acc: 0.7317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f60d4dc0a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH_lsKGfTv1-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e36cf10-0adb-455a-a171-a57e77f9b9b6"
      },
      "source": [
        "predictions = model.predict(xvalid_w2v)\n",
        "predictions = predictions.argmax(axis = -1)\n",
        "df = pd.DataFrame()\n",
        "df['new_col'] = predictions\n",
        "f1_score(yvalid, df['new_col'], average='micro')"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7316919191919192"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrVIEvgEUvEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = model.predict(test_w2v)\n",
        "test_pred = test_pred.argmax(axis = -1)\n",
        "\n",
        "te_res = pd.read_csv(\"drive/My Drive/datasets/Sentiment_Analysis_Analytics_vidhya_Medical/test_tOlRoBf.csv\")\n",
        "te_res['sentiment'] = test_pred\n",
        "\n",
        "submission = te_res[['unique_hash','sentiment']]\n",
        "submission.to_csv('model_result.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRs0x_p1csec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}