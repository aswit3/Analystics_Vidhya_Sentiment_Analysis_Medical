{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ELMo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswit3/Analystics_Vidhya_Sentiment_Analysis_Medical/blob/master/ELMo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDCh2K2n_oQV",
        "colab_type": "code",
        "outputId": "27cd9ef3-09e9-4efe-ce1c-de0cd1062a43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh4Skja9Afn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3EEGxMv-iwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr = pd.read_csv(\"drive/My Drive/datasets/Sentiment_Analysis_Analytics_vidhya_Medical/train_F3WbcTw.csv\")\n",
        "te = pd.read_csv(\"drive/My Drive/datasets/Sentiment_Analysis_Analytics_vidhya_Medical/test_tOlRoBf.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu3-t0ufCOP0",
        "colab_type": "code",
        "outputId": "bfe4387c-a91c-4d03-c31f-0bb339caa2fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tr.shape, te.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5279, 4), (2924, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SORo5JLTCzTx",
        "colab_type": "code",
        "outputId": "2790b923-1f2a-4ebb-91f4-2ca3057847f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "tr.head(2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>text</th>\n",
              "      <th>drug</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0</td>\n",
              "      <td>Autoimmune diseases tend to come in clusters. ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9eba8f80e7e20f3a2f48685530748fbfa95943e4</td>\n",
              "      <td>I can completely understand why you’d want to ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                unique_hash  ... sentiment\n",
              "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0  ...         2\n",
              "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4  ...         2\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iws8Gf7DC42w",
        "colab_type": "code",
        "outputId": "022adc75-524d-4ff8-c126-206fb107d99e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "te.head(2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>text</th>\n",
              "      <th>drug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
              "      <td>256 (previously stable on natalizumab), with 5...</td>\n",
              "      <td>fingolimod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
              "      <td>On fingolimod and have been since December 201...</td>\n",
              "      <td>fingolimod</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                unique_hash  ...        drug\n",
              "0  9e9a8166b84114aca147bf409f6f956635034c08  ...  fingolimod\n",
              "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a  ...  fingolimod\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DcoLyVDCtz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del tr[\"unique_hash\"]\n",
        "del te[\"unique_hash\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B0vwO3_I1Q7",
        "colab_type": "code",
        "outputId": "655e3a54-23d5-4279-c76c-3331341118d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tr[\"drug\"].value_counts()), len(te[\"drug\"].value_counts())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 95)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhkaA2TxDNhU",
        "colab_type": "code",
        "outputId": "47daa67d-5671-4f9a-f8df-e7e9a6c290a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tr.shape, te.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5279, 3), (2924, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tjqvCaACaFX",
        "colab_type": "code",
        "outputId": "a8e76305-8e7d-4675-9a73-0e89d669f3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tr_sentiment = tr[\"sentiment\"]\n",
        "tr_sentiment.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5279,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNnQQ7gUHVQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del tr[\"sentiment\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6B-EFIGHd_E",
        "colab_type": "code",
        "outputId": "5b4482af-e2df-4b46-fa85-31b669532b85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tr.shape, te.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5279, 2), (2924, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_aa4n5bHte6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trte = tr.append(te, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDywZ15AIN_4",
        "colab_type": "code",
        "outputId": "1facfc84-7cc3-4aec-a1c8-c0e25723e12c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trte.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8203, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_js6iwUG5t_",
        "colab_type": "code",
        "outputId": "fca6e412-a68b-4bc3-cc82-c7d7167855e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(trte[\"drug\"].value_counts())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qh_tIPJHHcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "clean_list = []\n",
        "\n",
        "for i, unclean_text in enumerate(trte[\"text\"]):\n",
        "  clean_text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', '', unclean_text)\n",
        "  clean_list.append(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBckeSFzOSyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trte[\"text\"] = clean_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsjTXJDvNGQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re, string, unicodedata\n",
        "import inflect\n",
        "import nltk\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuqLQn85NfFp",
        "colab_type": "code",
        "outputId": "6c1800d6-1506-40be-e70d-1ffdad2664ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCrKTgO4NkbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_non_ascii(words):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def to_lowercase(words):\n",
        "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def replace_numbers(words):\n",
        "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
        "    p = inflect.engine()\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word.isdigit():\n",
        "            new_word = p.number_to_words(word)\n",
        "            new_words.append(new_word)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word not in stopwords.words('english'):\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def stem_words(words):\n",
        "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
        "    stemmer = LancasterStemmer()\n",
        "    stems = []\n",
        "    for word in words:\n",
        "        stem = stemmer.stem(word)\n",
        "        stems.append(stem)\n",
        "    return stems\n",
        "\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "def normalize(words):\n",
        "    words = remove_non_ascii(words)\n",
        "    words = to_lowercase(words)\n",
        "    words = remove_punctuation(words)\n",
        "    words = replace_numbers(words)\n",
        "    words = remove_stopwords(words)\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZbvl46qNvy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_ls = []\n",
        "for i, unclean_text in enumerate(trte[\"text\"]):\n",
        "  words = nltk.word_tokenize(unclean_text)\n",
        "  words = normalize(words)\n",
        "  words_ls.append(\" \".join(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8XGbdQJN6K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trte['text'] = words_ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoqKGQ0jPbu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "840f1c4b-d777-453d-8ce0-d76c2aa00b74"
      },
      "source": [
        "text_tokens =trte['text']\n",
        "text_tokens.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8203,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5W5JamxPeU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt5xX7hCQAxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "option = 2\n",
        "\n",
        "if option == 1:\n",
        "  url = \"https://tfhub.dev/google/elmo/2\"\n",
        "  embed = hub.Module(url)\n",
        "elif option == 2:\n",
        "  url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
        "  embed = hub.Module(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdhSQD91Pwq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense\n",
        "\n",
        "input_text = Input(shape=(1,), dtype=tf.string)\n",
        "\n",
        "if option == 1:\n",
        "  def ELMoEmbedding(x):\n",
        "      return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
        "  embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
        "elif option == 2:\n",
        "  def UniversalEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)))\n",
        "  embedding = Lambda(UniversalEmbedding, output_shape=(512, ))(input_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Eu7BzI2SflA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras.layers as layers\n",
        "from keras.models import Model\n",
        "from keras.datasets import imdb\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import FastText\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import Input,Embedding,Dense,Flatten\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MISFQdpvRcTh",
        "colab_type": "code",
        "outputId": "af5c8f11-9630-4818-aaf2-63218dfde4ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_w2v = text_tokens[:5279]\n",
        "test_w2v = text_tokens[5279:]\n",
        "\n",
        "\n",
        "_, _, ytrain, yvalid = train_test_split(train_w2v, tr_sentiment,  \n",
        "                                                          random_state=42, \n",
        "                                                          test_size=0.3)\n",
        "\n",
        "\n",
        "\n",
        "print(train_w2v.shape, tr_sentiment.shape)\n",
        "print(ytrain.shape, yvalid.shape)\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5279,) (5279,)\n",
            "(3695,) (1584,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhi-_ujQSoPP",
        "colab_type": "code",
        "outputId": "2f652e8f-9ccd-49b7-ce99-0d409a65b3c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "epochs = 25\n",
        "batch_size = 1024\n",
        "loss = \"sparse_categorical_crossentropy\"\n",
        "optimizer = \"adam\"\n",
        "metrics = [\"accuracy\"]\n",
        "\n",
        "from keras import models\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
        "            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "x = Dense(256,activation =\"relu\")(embedding)\n",
        "preds = Dense(3,activation=\"softmax\")(x)\n",
        "model = Model(input_text,preds)\n",
        "\n",
        "model.compile(loss=loss,optimizer=optimizer,metrics= metrics)\n",
        "model.fit(train_w2v,tr_sentiment,epochs=epochs,batch_size=batch_size,callbacks=callbacks,validation_data=(train_w2v[:500],tr_sentiment[:500]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 19:39:40.584172 140383520290688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0725 19:39:40.629830 140383520290688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0725 19:39:40.657180 140383520290688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0725 19:39:40.754471 140383520290688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0725 19:39:40.785774 140383520290688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 5279 samples, validate on 500 samples\n",
            "Epoch 1/25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH_lsKGfTv1-",
        "colab_type": "code",
        "outputId": "8e36cf10-0adb-455a-a171-a57e77f9b9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions = model.predict(xvalid_w2v)\n",
        "predictions = predictions.argmax(axis = -1)\n",
        "df = pd.DataFrame()\n",
        "df['new_col'] = predictions\n",
        "f1_score(yvalid, df['new_col'], average='micro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7316919191919192"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrVIEvgEUvEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = model.predict(test_w2v)\n",
        "test_pred = test_pred.argmax(axis = -1)\n",
        "\n",
        "te_res = pd.read_csv(\"drive/My Drive/datasets/Sentiment_Analysis_Analytics_vidhya_Medical/test_tOlRoBf.csv\")\n",
        "te_res['sentiment'] = test_pred\n",
        "\n",
        "submission = te_res[['unique_hash','sentiment']]\n",
        "submission.to_csv('model_result.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRs0x_p1csec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}